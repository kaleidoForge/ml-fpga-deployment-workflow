# Course Instance: Mar del Plata 2025

## Context
- **Location:** Mar del Plata, Argentina
- **Duration:** Two-week intensive workshop
- **Audience:** Undergraduate and postgraduate students, researchers, and industry professionals
- **Format:** Hybrid (lectures + hands-on laboratories)
- **Enrollment:** 20 participants

## Educational Focus
This edition emphasized the end-to-end workflow from ML model design to FPGA deployment, with a strong focus on:
- Model compression techniques (quantization, pruning)
- High-Level Synthesis for ML inference
- System-level design considerations (power, signal integrity, EMC)

## Hardware and Tooling
- **FPGA platforms:** PYNQ-Z1/Z3, Zedboard, HyperFPGA
- **Toolchain:** Vivado HLS, Python-based ML stack
- **Deployment scope:** Single-board FPGA inference (educational reference)
## Labs and Demos Used
This course instance used the following modules from the repository:
- `labs`
- `demos`

## Observations and Iteration Notes
- Participants benefited from early exposure to hardware constraints.
- Additional time was required for FPGA toolchain setup.
- Future editions should include pre-configured environments.

## Related Outputs
- Associated paper: *Holistic Edge AI: From ML Models to Hardware-Aware Deployment". EDUCON2026*

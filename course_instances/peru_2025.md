# Course Instance: Perú - 2025

## Context
- **Location:** Lima, Perú
- **Duration:** One-week workshop (Total: 8hs)
- **Audience:** Professors Universidad Tecnológica de Perú
- **Format:** Online (lectures + demos)
- **Enrollment:** 20 participants

## Educational Focus
This edition emphasized the end-to-end workflow from ML model design to FPGA deployment, with a strong focus on:
- Model compression techniques (quantization, pruning, knowledge distillation).
- High-Level Synthesis for ML inference.
- SoC/FPGA deployment.

## Hardware and Tooling
- **FPGA platforms:** PYNQ-Z1, HyperFPGA
- **Toolchain:** Vivado HLS, Vivado, Python-based ML stack, PYNQ
- **Deployment scope:** Single-board FPGA inference (educational reference)
## Labs and Demos Used
This course instance used the following modules from the repository:
- `demos`

## Observations and Iteration Notes
- 
